{
 "cells": [
  {
   "cell_type": "markdown",
   "source": "## 8. Interactive Experimentation\n\nYou can modify the controller parameters and re-run the experiment to see how it affects behavior:",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Convert results to the same format as original method_out.json\noutput_results = {\n    \"baseline\": [],\n    \"proposed\": []\n}\n\nfor baseline_result, proposed_result in zip(results[\"baseline\"], results[\"proposed\"]):\n    output_results[\"baseline\"].append({\n        \"id\": baseline_result[\"id\"],\n        \"decision\": baseline_result[\"decision\"],\n        \"error\": baseline_result[\"error\"]\n    })\n    output_results[\"proposed\"].append({\n        \"id\": proposed_result[\"id\"],\n        \"decision\": proposed_result[\"decision\"],\n        \"error\": proposed_result[\"error\"]\n    })\n\n# Save results to JSON file (optional)\nwith open(\"method_out.json\", \"w\") as f:\n    json.dump(output_results, f, indent=2)\n\nprint(\"Results saved to 'method_out.json'\")\n\n# Show a sample of the JSON output\nprint(f\"\\nSample of first 3 results:\")\nprint(json.dumps({\n    \"baseline\": output_results[\"baseline\"][:3],\n    \"proposed\": output_results[\"proposed\"][:3]\n}, indent=2))",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 7. Export Results\n\nExport the results in JSON format (equivalent to the original method_out.json output):",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Show first 10 results for comparison\nprint(\"First 10 Results Comparison:\")\nprint(\"=\" * 60)\nprint(f\"{'ID':<12} {'Difficulty':<10} {'Error':<7} {'Baseline':<10} {'Proposed':<10}\")\nprint(\"-\" * 60)\n\nfor i in range(min(10, len(sample_data))):\n    sample = sample_data[i]\n    baseline_result = results[\"baseline\"][i]\n    proposed_result = results[\"proposed\"][i]\n    \n    print(f\"{sample['id']:<12} {sample['difficulty']:<10.3f} {str(baseline_result['error']):<7} \"\n          f\"{baseline_result['decision']:<10} {proposed_result['decision']:<10}\")\n\n# Analyze decision transitions in the DKW controller\nprint(f\"\\n\\nDecision Transitions in DKW Controller:\")\nprint(\"=\" * 40)\ntransitions = []\nprev_decision = None\n\nfor result in results[\"proposed\"]:\n    if prev_decision is not None and result[\"decision\"] != prev_decision:\n        transitions.append((prev_decision, result[\"decision\"]))\n    prev_decision = result[\"decision\"]\n\nprint(f\"Total decision changes: {len(transitions)}\")\nif transitions:\n    fission_to_fusion = sum(1 for t in transitions if t == (\"fission\", \"fusion\"))\n    fusion_to_fission = sum(1 for t in transitions if t == (\"fusion\", \"fission\"))\n    print(f\"Fission → Fusion: {fission_to_fusion}\")\n    print(f\"Fusion → Fission: {fusion_to_fission}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 6. Detailed Analysis\n\nLet's examine the first few results and analyze the decision-making pattern:",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Run the experiment\nresults = run_experiment(sample_data)\n\n# Display summary statistics\nprint(\"Experiment Results Summary:\")\nprint(\"=\" * 50)\n\n# Count decisions for each method\nbaseline_decisions = [r[\"decision\"] for r in results[\"baseline\"]]\nproposed_decisions = [r[\"decision\"] for r in results[\"proposed\"]]\n\nprint(f\"\\nBaseline (always fission):\")\nprint(f\"  Fission decisions: {baseline_decisions.count('fission')}\")\nprint(f\"  Fusion decisions: {baseline_decisions.count('fusion')}\")\n\nprint(f\"\\nProposed (DKW controller):\")\nprint(f\"  Fission decisions: {proposed_decisions.count('fission')}\")\nprint(f\"  Fusion decisions: {proposed_decisions.count('fusion')}\")\n\n# Count errors\nbaseline_errors = sum(r[\"error\"] for r in results[\"baseline\"])\nproposed_errors = sum(r[\"error\"] for r in results[\"proposed\"])\n\nprint(f\"\\nError Rates:\")\nprint(f\"  Baseline error rate: {baseline_errors / len(results['baseline']):.3f}\")\nprint(f\"  Proposed error rate: {proposed_errors / len(results['proposed']):.3f}\")\n\nprint(f\"\\nTotal samples processed: {len(sample_data)}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 5. Run the Experiment\n\nLet's run the experiment and analyze the results:",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "def run_experiment(data):\n    \"\"\"Run DKW controller experiment with inline data.\"\"\"\n    controller = DKWController()\n    results = {\"baseline\": [], \"proposed\": []}\n\n    for example in data:\n        # Simulate error occurrence based on difficulty\n        error = np.random.random() < example[\"difficulty\"]\n        controller.add_observation(float(error))\n        decision = controller.decide()\n\n        results[\"proposed\"].append({\n            \"id\": example[\"id\"],\n            \"decision\": decision,\n            \"error\": error,\n        })\n        results[\"baseline\"].append({\n            \"id\": example[\"id\"],\n            \"decision\": \"fission\",  # Always conservative\n            \"error\": error,\n        })\n\n    return results",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 4. Experiment Function\n\nThe experiment function compares the DKW controller's decisions against a baseline that always chooses the conservative \"fission\" mode.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Sample experimental data (replaces reading from \"../dataset_001/data_out.json\")\nsample_data = [\n    {\"id\": \"example_000\", \"difficulty\": 0.05},\n    {\"id\": \"example_001\", \"difficulty\": 0.03},\n    {\"id\": \"example_002\", \"difficulty\": 0.15},\n    {\"id\": \"example_003\", \"difficulty\": 0.08},\n    {\"id\": \"example_004\", \"difficulty\": 0.02},\n    {\"id\": \"example_005\", \"difficulty\": 0.12},\n    {\"id\": \"example_006\", \"difficulty\": 0.07},\n    {\"id\": \"example_007\", \"difficulty\": 0.18},\n    {\"id\": \"example_008\", \"difficulty\": 0.04},\n    {\"id\": \"example_009\", \"difficulty\": 0.11}\n] * 15  # Repeat to get enough samples (150 total)\n\n# Add unique IDs\nfor i, item in enumerate(sample_data):\n    item[\"id\"] = f\"example_{i:03d}\"\n\nprint(f\"Created {len(sample_data)} sample data points\")\nprint(f\"Sample difficulty range: {min(d['difficulty'] for d in sample_data):.3f} - {max(d['difficulty'] for d in sample_data):.3f}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 3. Sample Data\n\nInstead of reading from external JSON files, we'll define our experimental data inline. This data simulates examples with varying difficulty levels.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "@dataclass\nclass DKWController:\n    \"\"\"DKW-guided fusion/fission controller.\"\"\"\n    epsilon_target: float = 0.10\n    delta: float = 0.05\n    min_samples: int = 100\n    hysteresis: float = 0.05\n\n    samples: list = field(default_factory=list)\n    current_state: str = \"fission\"\n\n    def dkw_epsilon(self, n: int) -> float:\n        \"\"\"Compute DKW epsilon for n samples.\"\"\"\n        if n < 2:\n            return 1.0\n        return np.sqrt(np.log(2 / self.delta) / (2 * n))\n\n    def add_observation(self, error: float) -> None:\n        \"\"\"Add error observation for calibration.\"\"\"\n        self.samples.append(error)\n\n    def decide(self) -> str:\n        \"\"\"Make fusion/fission decision with DKW guarantee.\"\"\"\n        n = len(self.samples)\n        if n < self.min_samples:\n            return self.current_state\n\n        epsilon = self.dkw_epsilon(n)\n        empirical_error = np.mean(self.samples[-self.min_samples:])\n        error_upper_bound = empirical_error + epsilon\n\n        if self.current_state == \"fusion\":\n            if error_upper_bound > self.epsilon_target + self.hysteresis:\n                self.current_state = \"fission\"\n        else:\n            if error_upper_bound < self.epsilon_target - self.hysteresis:\n                self.current_state = \"fusion\"\n\n        return self.current_state",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 2. DKW Controller Class\n\nThe `DKWController` class implements a decision controller that uses the Dvoretzky-Kiefer-Wolfowitz inequality to make statistically principled decisions between \"fusion\" and \"fission\" modes.\n\n### Key Parameters:\n- `epsilon_target`: Target error rate threshold\n- `delta`: Confidence parameter for DKW bound  \n- `min_samples`: Minimum samples before making decisions\n- `hysteresis`: Prevents rapid oscillation between modes",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "\"\"\"DKW Controller Implementation.\"\"\"\nimport json\nimport numpy as np\nfrom dataclasses import dataclass, field\n\n# Set random seed for reproducible results\nnp.random.seed(42)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 1. Dependencies and Imports",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "# DKW Controller Implementation Demo\n\nThis notebook demonstrates a **DKW-guided fusion/fission controller** that makes decisions based on error observations with statistical guarantees.\n\n## Overview\nThe controller uses the Dvoretzky-Kiefer-Wolfowitz (DKW) inequality to provide confidence bounds on empirical error rates, enabling principled decisions between \"fusion\" and \"fission\" modes with theoretical guarantees.",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}