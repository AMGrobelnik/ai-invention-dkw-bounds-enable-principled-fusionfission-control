{
 "cells": [
  {
   "cell_type": "code",
   "source": "# Show the results in the same format as the original script would save\nprint(\"üìù RESULTS OUTPUT (method_out.json format):\")\nprint(\"=\" * 50)\n\n# Convert results to JSON-serializable format\nformatted_results = {\n    \"baseline\": [\n        {\n            \"id\": r[\"id\"],\n            \"decision\": r[\"decision\"], \n            \"error\": r[\"error\"]\n        }\n        for r in experiment_results[\"baseline\"]\n    ],\n    \"proposed\": [\n        {\n            \"id\": r[\"id\"],\n            \"decision\": r[\"decision\"],\n            \"error\": r[\"error\"] \n        }\n        for r in experiment_results[\"proposed\"]\n    ]\n}\n\n# Display as formatted JSON\nprint(json.dumps(formatted_results, indent=2))\n\n# Optional: Save to file (uncomment to enable)\n# with open(\"method_out.json\", \"w\") as f:\n#     json.dump(formatted_results, f, indent=2)\n# print(\"\\n‚úì Results saved to method_out.json\")\n\nprint(f\"\\n‚úÖ NOTEBOOK COMPLETE!\")\nprint(f\"   - DKW Controller implemented and tested\")\nprint(f\"   - {len(test_data)} examples processed\")\nprint(f\"   - Baseline vs. proposed comparison completed\")\nprint(f\"   - Ready for further experimentation!\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Save Results (Optional)\n\nThe original script saved results to `method_out.json`. Here we show the equivalent output format and provide an option to save to file if desired.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Experiment with different parameters!\n# Try changing these values and re-running to see the effects:\n\ndef experiment_with_parameters(epsilon_target=0.15, delta=0.05, min_samples=50, hysteresis=0.02):\n    \"\"\"Run experiment with custom parameters.\"\"\"\n    print(f\"üß™ CUSTOM EXPERIMENT\")\n    print(f\"   epsilon_target: {epsilon_target} (target error rate)\")\n    print(f\"   delta: {delta} (confidence parameter)\") \n    print(f\"   min_samples: {min_samples} (minimum observations)\")\n    print(f\"   hysteresis: {hysteresis} (anti-oscillation buffer)\")\n    print()\n    \n    # Create custom controller\n    custom_controller = DKWController(\n        epsilon_target=epsilon_target,\n        delta=delta, \n        min_samples=min_samples,\n        hysteresis=hysteresis\n    )\n    \n    # Run experiment\n    custom_results = {\"baseline\": [], \"proposed\": []}\n    \n    for example in test_data:\n        error = np.random.random() < example[\"difficulty\"]\n        custom_controller.add_observation(float(error))\n        decision = custom_controller.decide()\n        \n        custom_results[\"proposed\"].append({\n            \"id\": example[\"id\"],\n            \"decision\": decision, \n            \"error\": error,\n        })\n        custom_results[\"baseline\"].append({\n            \"id\": example[\"id\"],\n            \"decision\": \"fission\",\n            \"error\": error,\n        })\n    \n    # Quick analysis\n    proposed_fusion_count = sum(1 for r in custom_results[\"proposed\"] if r[\"decision\"] == \"fusion\")\n    proposed_error_count = sum(1 for r in custom_results[\"proposed\"] if r[\"error\"])\n    \n    print(f\"üìä Results: {proposed_fusion_count} fusion decisions, {proposed_error_count} errors\")\n    return custom_results\n\n# Try the default parameters\nprint(\"=\" * 50)\ndefault_results = experiment_with_parameters()\n\nprint(\"\\n\" + \"=\" * 50)\nprint(\"Try experimenting with different parameters!\")\nprint(\"For example:\")\nprint(\"  experiment_with_parameters(epsilon_target=0.05)  # More aggressive\")\nprint(\"  experiment_with_parameters(epsilon_target=0.20)  # More conservative\") \nprint(\"  experiment_with_parameters(min_samples=20)       # Faster decisions\")\nprint(\"  experiment_with_parameters(hysteresis=0.10)      # Less switching\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Interactive Experimentation\n\nTry modifying the controller parameters to see how they affect performance! This section lets you explore different configurations.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Analyze results\ndef analyze_results(results):\n    \"\"\"Analyze experiment results.\"\"\"\n    baseline = results[\"baseline\"] \n    proposed = results[\"proposed\"]\n    \n    print(\"=== EXPERIMENT RESULTS ANALYSIS ===\\n\")\n    \n    # Count decisions\n    baseline_fission = sum(1 for r in baseline if r[\"decision\"] == \"fission\")\n    baseline_fusion = sum(1 for r in baseline if r[\"decision\"] == \"fusion\") \n    proposed_fission = sum(1 for r in proposed if r[\"decision\"] == \"fission\")\n    proposed_fusion = sum(1 for r in proposed if r[\"decision\"] == \"fusion\")\n    \n    print(\"üìä DECISION BREAKDOWN:\")\n    print(f\"  Baseline:  {baseline_fission} fission, {baseline_fusion} fusion\")\n    print(f\"  Proposed:  {proposed_fission} fission, {proposed_fusion} fusion\")\n    \n    # Count errors\n    baseline_errors = sum(1 for r in baseline if r[\"error\"])\n    proposed_errors = sum(1 for r in proposed if r[\"error\"])\n    \n    print(f\"\\n‚ùå ERROR COUNTS:\")\n    print(f\"  Baseline:  {baseline_errors}/{len(baseline)} errors ({baseline_errors/len(baseline):.1%})\")\n    print(f\"  Proposed:  {proposed_errors}/{len(proposed)} errors ({proposed_errors/len(proposed):.1%})\")\n    \n    # Performance metrics (assuming fusion is higher performance when no errors)\n    baseline_performance = baseline_fusion  # Only fusion gives performance benefit\n    proposed_performance = proposed_fusion  \n    \n    print(f\"\\nüöÄ PERFORMANCE OPPORTUNITIES:\")\n    print(f\"  Baseline:  {baseline_performance} high-performance decisions\")  \n    print(f\"  Proposed:  {proposed_performance} high-performance decisions\")\n    \n    if proposed_performance > baseline_performance:\n        print(f\"  üìà Proposed approach used {proposed_performance - baseline_performance} more high-performance decisions\")\n    \n    # Show decision timeline\n    print(f\"\\nüìã DECISION TIMELINE:\")\n    print(f\"{'Example':<12} {'Error':<8} {'Baseline':<10} {'Proposed':<10}\")\n    print(\"-\" * 42)\n    for i, (b, p) in enumerate(zip(baseline, proposed)):\n        error_symbol = \"‚úó\" if b[\"error\"] else \"‚úì\"\n        highlight = \" üîÑ\" if b[\"decision\"] != p[\"decision\"] else \"\"\n        print(f\"{b['id']:<12} {error_symbol:<8} {b['decision']:<10} {p['decision']:<10}{highlight}\")\n    \n    return {\n        \"baseline_errors\": baseline_errors,\n        \"proposed_errors\": proposed_errors, \n        \"baseline_performance\": baseline_performance,\n        \"proposed_performance\": proposed_performance\n    }\n\n# Analyze our experiment results\nanalysis = analyze_results(experiment_results)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Results Analysis\n\nLet's analyze the performance of both approaches and see how the DKW controller adapts its decisions based on the observed error rates.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "def run_experiment(data):\n    \"\"\"Run DKW controller experiment.\"\"\"\n    controller = DKWController()\n    results = {\"baseline\": [], \"proposed\": []}\n    \n    print(\"Running experiment...\")\n    print(f\"{'Example':<12} {'Difficulty':<12} {'Error':<8} {'Baseline':<10} {'Proposed':<10} {'Samples':<8}\")\n    print(\"-\" * 70)\n    \n    for i, example in enumerate(data):\n        # Simulate error occurrence based on difficulty\n        error = np.random.random() < example[\"difficulty\"]\n        controller.add_observation(float(error))\n        decision = controller.decide()\n\n        # Store results\n        results[\"proposed\"].append({\n            \"id\": example[\"id\"],\n            \"decision\": decision,\n            \"error\": error,\n        })\n        results[\"baseline\"].append({\n            \"id\": example[\"id\"],\n            \"decision\": \"fission\",  # Always conservative\n            \"error\": error,\n        })\n        \n        # Print progress\n        print(f\"{example['id']:<12} {example['difficulty']:<12.3f} {'‚úó' if error else '‚úì':<8} {'fission':<10} {decision:<10} {len(controller.samples):<8}\")\n    \n    print(\"\\n‚úì Experiment completed\")\n    return results\n\n# Run the experiment with our inline data\nexperiment_results = run_experiment(test_data)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Experiment Function\n\nThe `run_experiment` function compares two approaches:\n\n1. **Baseline**: Always uses conservative \"fission\" mode\n2. **Proposed**: Uses DKW controller to adaptively switch between modes\n\nThe function simulates errors based on each example's difficulty level and tracks the controller's decisions over time.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Inline test data - simulates reading from \"../dataset_001/data_out.json\"\n# Each example has an ID and difficulty level (0.0 = easy, 1.0 = very hard)\ntest_data = [\n    {\"id\": \"example_000\", \"difficulty\": 0.05},  # Very easy - 5% error chance\n    {\"id\": \"example_001\", \"difficulty\": 0.08},  # Easy - 8% error chance  \n    {\"id\": \"example_002\", \"difficulty\": 0.15},  # Medium - 15% error chance\n    {\"id\": \"example_003\", \"difficulty\": 0.12},  # Medium-easy - 12% error chance\n    {\"id\": \"example_004\", \"difficulty\": 0.18},  # Medium-hard - 18% error chance\n    {\"id\": \"example_005\", \"difficulty\": 0.22},  # Hard - 22% error chance\n    {\"id\": \"example_006\", \"difficulty\": 0.09},  # Easy - 9% error chance\n    {\"id\": \"example_007\", \"difficulty\": 0.14},  # Medium - 14% error chance\n    {\"id\": \"example_008\", \"difficulty\": 0.25},  # Very hard - 25% error chance\n    {\"id\": \"example_009\", \"difficulty\": 0.11},  # Medium-easy - 11% error chance\n]\n\n# Expected results data - what the original script would have output\nexpected_results = {\n  \"baseline\": [\n    {\n      \"id\": \"example_000\",\n      \"decision\": \"fission\", \n      \"error\": False\n    },\n    {\n      \"id\": \"example_001\",\n      \"decision\": \"fission\",\n      \"error\": False\n    },\n    {\n      \"id\": \"example_002\", \n      \"decision\": \"fission\",\n      \"error\": True\n    }\n  ],\n  \"proposed\": [\n    {\n      \"id\": \"example_000\",\n      \"decision\": \"fission\",\n      \"error\": False\n    },\n    {\n      \"id\": \"example_001\",\n      \"decision\": \"fusion\", \n      \"error\": False\n    },\n    {\n      \"id\": \"example_002\",\n      \"decision\": \"fusion\",\n      \"error\": True\n    }\n  ]\n}\n\nprint(f\"‚úì Loaded {len(test_data)} test examples\")\nprint(f\"‚úì Loaded expected results for comparison\")\nprint(f\"  - Difficulty range: {min(ex['difficulty'] for ex in test_data):.2f} to {max(ex['difficulty'] for ex in test_data):.2f}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Inline Test Data\n\nInstead of reading from external JSON files, we'll define the test data directly in the notebook to make it self-contained.\n\nThe data simulates examples with varying difficulty levels that affect error probability.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "@dataclass\nclass DKWController:\n    \"\"\"DKW-guided fusion/fission controller.\"\"\"\n    epsilon_target: float = 0.10\n    delta: float = 0.05\n    min_samples: int = 100\n    hysteresis: float = 0.05\n\n    samples: list = field(default_factory=list)\n    current_state: str = \"fission\"\n\n    def dkw_epsilon(self, n: int) -> float:\n        \"\"\"Compute DKW epsilon for n samples.\"\"\"\n        if n < 2:\n            return 1.0\n        return np.sqrt(np.log(2 / self.delta) / (2 * n))\n\n    def add_observation(self, error: float) -> None:\n        \"\"\"Add error observation for calibration.\"\"\"\n        self.samples.append(error)\n\n    def decide(self) -> str:\n        \"\"\"Make fusion/fission decision with DKW guarantee.\"\"\"\n        n = len(self.samples)\n        if n < self.min_samples:\n            return self.current_state\n\n        epsilon = self.dkw_epsilon(n)\n        empirical_error = np.mean(self.samples[-self.min_samples:])\n        error_upper_bound = empirical_error + epsilon\n\n        if self.current_state == \"fusion\":\n            if error_upper_bound > self.epsilon_target + self.hysteresis:\n                self.current_state = \"fission\"\n        else:\n            if error_upper_bound < self.epsilon_target - self.hysteresis:\n                self.current_state = \"fusion\"\n\n        return self.current_state\n\n# Test the controller creation\ncontroller = DKWController()\nprint(f\"‚úì Created DKW Controller\")\nprint(f\"  - Target error rate: {controller.epsilon_target}\")\nprint(f\"  - Confidence level: {1-controller.delta:.0%}\")\nprint(f\"  - Initial state: {controller.current_state}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## DKW Controller Class\n\nThe `DKWController` implements a statistical decision-making system using the **Dvoretzky-Kiefer-Wolfowitz inequality**.\n\n### Key Parameters:\n- `epsilon_target`: Target error rate threshold (default: 0.10 = 10%)\n- `delta`: Confidence level parameter for DKW bound (default: 0.05 = 95% confidence)\n- `min_samples`: Minimum observations before making decisions (default: 100)\n- `hysteresis`: Prevents oscillation between modes (default: 0.05)\n\n### How it works:\n1. **Collects error observations** from the system\n2. **Computes DKW epsilon** - statistical bound on estimation error\n3. **Calculates upper confidence bound** on error rate \n4. **Makes switching decisions** with hysteresis to prevent oscillation",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "\"\"\"DKW Controller Implementation.\"\"\"\nimport json\nimport numpy as np\nfrom dataclasses import dataclass, field\n\n# Set random seed for reproducible results\nnp.random.seed(42)\n\nprint(\"‚úì Imported required libraries\")\nprint(\"‚úì Set random seed for reproducibility\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "# DKW Controller Implementation Demo\n\nThis notebook demonstrates a **DKW-guided fusion/fission controller** that uses the Dvoretzky-Kiefer-Wolfowitz (DKW) inequality to make statistically-grounded decisions between fusion and fission modes.\n\n## Overview\n- **Artifact ID**: experiment_001\n- **Original file**: method.py\n- **Purpose**: Adaptive controller that switches between fusion/fission based on error rate observations\n\nThe controller uses statistical guarantees to decide when to switch between:\n- **Fusion mode**: More aggressive, higher performance but potentially higher error rate\n- **Fission mode**: Conservative, lower performance but more reliable",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}