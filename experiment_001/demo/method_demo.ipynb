{
 "cells": [
  {
   "cell_type": "code",
   "source": "# Display sample of the results that would be saved\nprint(\"Sample output (first 5 examples):\")\nprint(json.dumps({\n    \"baseline\": results[\"baseline\"][:5],\n    \"proposed\": results[\"proposed\"][:5]\n}, indent=2))\n\nprint(f\"\\n... and {len(results['baseline'])-5} more examples\")\n\n# Optionally save results to file (uncomment to enable)\n# with open(\"method_out.json\", \"w\") as f:\n#     json.dump(results, f, indent=2)\n# print(\"Results saved to method_out.json\")\n\nprint(\"\\nðŸŽ‰ Notebook demo complete! You can now experiment with different parameters above.\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Output Results\n\nThe original script would save results to `method_out.json`. Here's what that output would look like:",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Try different parameter settings\ndef test_controller_params(epsilon_target=0.10, delta=0.05, min_samples=100, hysteresis=0.05):\n    \"\"\"Test controller with custom parameters.\"\"\"\n    \n    # Create custom controller\n    custom_controller = DKWController(\n        epsilon_target=epsilon_target,\n        delta=delta, \n        min_samples=min_samples,\n        hysteresis=hysteresis\n    )\n    \n    # Run on sample data\n    np.random.seed(42)  # For reproducible results\n    custom_results = {\"baseline\": [], \"proposed\": []}\n    \n    for example in sample_data:\n        error = np.random.random() < example[\"difficulty\"]\n        custom_controller.add_observation(float(error))\n        decision = custom_controller.decide()\n        \n        custom_results[\"proposed\"].append({\n            \"id\": example[\"id\"],\n            \"decision\": decision,\n            \"error\": error,\n        })\n    \n    # Calculate metrics\n    total = len(custom_results[\"proposed\"])\n    errors = sum(1 for r in custom_results[\"proposed\"] if r['error'])\n    fusions = sum(1 for r in custom_results[\"proposed\"] if r['decision'] == 'fusion')\n    \n    print(f\"Parameters: target={epsilon_target:.2f}, delta={delta:.2f}, min_samples={min_samples}, hysteresis={hysteresis:.2f}\")\n    print(f\"Results: {errors}/{total} errors ({errors/total*100:.1f}%), {fusions}/{total} fusions ({fusions/total*100:.1f}%)\")\n    \n    return custom_results\n\n# Test with default parameters\nprint(\"=== Default Parameters ===\")\ntest_controller_params()\n\n# Try more aggressive settings\nprint(\"\\n=== More Aggressive (lower target, less hysteresis) ===\")\ntest_controller_params(epsilon_target=0.15, hysteresis=0.02)\n\n# Try more conservative settings  \nprint(\"\\n=== More Conservative (higher min samples, more hysteresis) ===\")\ntest_controller_params(min_samples=150, hysteresis=0.08)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Interactive Exploration\n\nTry experimenting with different controller parameters to see how they affect the behavior:",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "import matplotlib.pyplot as plt\n\n# Create visualization of results\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n\n# Plot 1: Decision timeline for first 50 examples\ndecisions = [1 if r['decision'] == 'fusion' else 0 for r in results['proposed'][:50]]\nerrors = [1 if r['error'] else 0 for r in results['proposed'][:50]]\n\nax1.plot(decisions, 'b-', linewidth=2, label='Decision (1=fusion, 0=fission)')\nax1.scatter(range(len(errors)), errors, c=['red' if e else 'green' for e in errors], \n           alpha=0.6, label='Errors (red=error, green=success)')\nax1.set_xlabel('Example Number')\nax1.set_ylabel('Decision/Error')\nax1.set_title('DKW Controller Decisions vs Errors (First 50 Examples)')\nax1.legend()\nax1.grid(True, alpha=0.3)\n\n# Plot 2: Cumulative error rates\ncumulative_proposed = np.cumsum([r['error'] for r in results['proposed']]) / np.arange(1, len(results['proposed']) + 1)\ncumulative_baseline = np.cumsum([r['error'] for r in results['baseline']]) / np.arange(1, len(results['baseline']) + 1)\n\nax2.plot(cumulative_proposed, 'b-', linewidth=2, label='DKW Controller')\nax2.plot(cumulative_baseline, 'r--', linewidth=2, label='Baseline (always fission)')\nax2.axhline(y=0.10, color='gray', linestyle=':', alpha=0.7, label='Target error rate (10%)')\nax2.set_xlabel('Example Number')\nax2.set_ylabel('Cumulative Error Rate')\nax2.set_title('Cumulative Error Rates')\nax2.legend()\nax2.grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.show()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Set random seed for reproducible results\nnp.random.seed(42)\n\n# Run the experiment\nresults = run_experiment(sample_data)\n\n# Print summary statistics\nprint(\"=== EXPERIMENT RESULTS ===\")\nprint(f\"Total examples processed: {len(results['baseline'])}\")\nprint()\n\n# Baseline (always fission) results\nbaseline_errors = sum(1 for r in results['baseline'] if r['error'])\nbaseline_fissions = sum(1 for r in results['baseline'] if r['decision'] == 'fission')\nprint(f\"BASELINE (always fission):\")\nprint(f\"  Errors: {baseline_errors}/{len(results['baseline'])} ({baseline_errors/len(results['baseline'])*100:.1f}%)\")\nprint(f\"  Fission decisions: {baseline_fissions}/{len(results['baseline'])} ({baseline_fissions/len(results['baseline'])*100:.1f}%)\")\nprint()\n\n# Proposed method results\nproposed_errors = sum(1 for r in results['proposed'] if r['error'])\nproposed_fusions = sum(1 for r in results['proposed'] if r['decision'] == 'fusion')\nproposed_fissions = sum(1 for r in results['proposed'] if r['decision'] == 'fission')\nprint(f\"PROPOSED (DKW controller):\")\nprint(f\"  Errors: {proposed_errors}/{len(results['proposed'])} ({proposed_errors/len(results['proposed'])*100:.1f}%)\")\nprint(f\"  Fusion decisions: {proposed_fusions}/{len(results['proposed'])} ({proposed_fusions/len(results['proposed'])*100:.1f}%)\")\nprint(f\"  Fission decisions: {proposed_fissions}/{len(results['proposed'])} ({proposed_fissions/len(results['proposed'])*100:.1f}%)\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Running the Experiment\n\nNow let's run the DKW controller experiment and compare it against a baseline that always chooses the conservative \"fission\" mode.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "def run_experiment(data):\n    \"\"\"Run DKW controller experiment with inlined data.\"\"\"\n    controller = DKWController()\n    results = {\"baseline\": [], \"proposed\": []}\n\n    for example in data:\n        # Simulate error occurrence based on difficulty\n        error = np.random.random() < example[\"difficulty\"]\n        controller.add_observation(float(error))\n        decision = controller.decide()\n\n        results[\"proposed\"].append({\n            \"id\": example[\"id\"],\n            \"decision\": decision,\n            \"error\": error,\n        })\n        results[\"baseline\"].append({\n            \"id\": example[\"id\"],\n            \"decision\": \"fission\",  # Always conservative\n            \"error\": error,\n        })\n\n    return results\n\nprint(\"Experiment function defined successfully!\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Sample input data (inlined to make notebook self-contained)\n# This replaces the original data loading from \"../dataset_001/data_out.json\"\n\nsample_data = [\n    {\"id\": \"example_000\", \"difficulty\": 0.05},\n    {\"id\": \"example_001\", \"difficulty\": 0.08},\n    {\"id\": \"example_002\", \"difficulty\": 0.15},\n    {\"id\": \"example_003\", \"difficulty\": 0.03},\n    {\"id\": \"example_004\", \"difficulty\": 0.12},\n    {\"id\": \"example_005\", \"difficulty\": 0.07},\n    {\"id\": \"example_006\", \"difficulty\": 0.20},\n    {\"id\": \"example_007\", \"difficulty\": 0.02},\n    {\"id\": \"example_008\", \"difficulty\": 0.18},\n    {\"id\": \"example_009\", \"difficulty\": 0.11},\n]\n\n# Add more examples to reach minimum sample threshold\nfor i in range(10, 150):\n    difficulty = np.random.beta(2, 8)  # Most examples have low difficulty\n    sample_data.append({\n        \"id\": f\"example_{i:03d}\",\n        \"difficulty\": difficulty\n    })\n\nprint(f\"Generated {len(sample_data)} sample examples\")\nprint(f\"Difficulty range: {min(ex['difficulty'] for ex in sample_data):.3f} - {max(ex['difficulty'] for ex in sample_data):.3f}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Understanding the DKW Method\n\nThe **Dvoretzky-Kiefer-Wolfowitz (DKW) inequality** provides statistical confidence bounds for empirical error rates. \n\nKey parameters:\n- `epsilon_target`: Target error rate threshold (10% by default)\n- `delta`: Confidence level parameter (5% by default, giving 95% confidence)\n- `min_samples`: Minimum observations before making decisions (100 by default)\n- `hysteresis`: Prevents oscillation between states (5% by default)\n\nThe controller computes an upper confidence bound on the error rate and uses it to make reliable fusion/fission decisions.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "\"\"\"DKW Controller Implementation.\"\"\"\nimport json\nimport numpy as np\nfrom dataclasses import dataclass, field\n\n@dataclass\nclass DKWController:\n    \"\"\"DKW-guided fusion/fission controller.\"\"\"\n    epsilon_target: float = 0.10\n    delta: float = 0.05\n    min_samples: int = 100\n    hysteresis: float = 0.05\n\n    samples: list = field(default_factory=list)\n    current_state: str = \"fission\"\n\n    def dkw_epsilon(self, n: int) -> float:\n        \"\"\"Compute DKW epsilon for n samples.\"\"\"\n        if n < 2:\n            return 1.0\n        return np.sqrt(np.log(2 / self.delta) / (2 * n))\n\n    def add_observation(self, error: float) -> None:\n        \"\"\"Add error observation for calibration.\"\"\"\n        self.samples.append(error)\n\n    def decide(self) -> str:\n        \"\"\"Make fusion/fission decision with DKW guarantee.\"\"\"\n        n = len(self.samples)\n        if n < self.min_samples:\n            return self.current_state\n\n        epsilon = self.dkw_epsilon(n)\n        empirical_error = np.mean(self.samples[-self.min_samples:])\n        error_upper_bound = empirical_error + epsilon\n\n        if self.current_state == \"fusion\":\n            if error_upper_bound > self.epsilon_target + self.hysteresis:\n                self.current_state = \"fission\"\n        else:\n            if error_upper_bound < self.epsilon_target - self.hysteresis:\n                self.current_state = \"fusion\"\n\n        return self.current_state\n\nprint(\"DKW Controller class loaded successfully!\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "# DKW Controller Implementation Demo\n\n**Artifact ID:** experiment_001  \n**Original File:** method.py\n\nThis notebook demonstrates a DKW-guided fusion/fission controller that makes adaptive decisions based on error observations while providing statistical guarantees through the Dvoretzky-Kiefer-Wolfowitz (DKW) inequality.\n\n## Overview\n\nThe DKW controller adaptively switches between:\n- **Fusion mode**: More aggressive/efficient processing\n- **Fission mode**: Conservative/safe processing\n\nThe controller uses statistical confidence bounds to ensure reliable decision-making with probabilistic guarantees.",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}