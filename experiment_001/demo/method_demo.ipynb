{
 "cells": [
  {
   "cell_type": "code",
   "source": "# Save results to JSON (replicating original script functionality)\nwith open(\"method_out.json\", \"w\") as f:\n    json.dump(results, f, indent=2)\nprint(\"âœ… Results saved to method_out.json\")\n\nprint(\"\\n\" + \"=\"*50)\nprint(\"ðŸ§ª EXPERIMENT WITH DIFFERENT PARAMETERS\")\nprint(\"=\"*50)\nprint(\"Try changing these parameters in the DKWController and re-run:\")\nprint(\"â€¢ epsilon_target: Target error threshold (default: 0.10)\")\nprint(\"â€¢ delta: Confidence level (default: 0.05)\")  \nprint(\"â€¢ min_samples: Minimum samples before deciding (default: 100)\")\nprint(\"â€¢ hysteresis: Oscillation prevention margin (default: 0.05)\")\n\n# Example of parameter experimentation\nprint(f\"\\nðŸ“Š Quick parameter comparison:\")\nconfigs = [\n    {\"name\": \"Conservative\", \"epsilon_target\": 0.05, \"hysteresis\": 0.02},\n    {\"name\": \"Aggressive\", \"epsilon_target\": 0.15, \"hysteresis\": 0.08},\n    {\"name\": \"Quick Decision\", \"min_samples\": 50},\n]\n\nfor config in configs:\n    # Create controller with modified parameters\n    controller = DKWController(**config)\n    test_results = {\"proposed\": []}\n    \n    for example in full_dataset[:50]:  # Use first 50 examples for quick test\n        error = np.random.random() < example[\"difficulty\"] \n        controller.add_observation(float(error))\n        decision = controller.decide()\n        test_results[\"proposed\"].append({\"decision\": decision, \"error\": error})\n    \n    fusion_rate = sum(1 for r in test_results[\"proposed\"] if r[\"decision\"] == \"fusion\") / len(test_results[\"proposed\"])\n    error_rate = sum(r[\"error\"] for r in test_results[\"proposed\"]) / len(test_results[\"proposed\"])\n    \n    print(f\"  {config['name']}: {fusion_rate:.1%} fusion, {error_rate:.3f} error rate\")\n\nprint(f\"\\nðŸ“ The notebook is now self-contained and ready for experimentation!\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Interactive Experimentation & Results Export\n\nTry modifying the controller parameters and re-running the experiment to see how they affect performance. You can also save the results in the same format as the original script.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Create visualizations\nfig, axes = plt.subplots(2, 2, figsize=(15, 10))\n\n# 1. Decision timeline\ndecisions_numeric = [1 if d == \"fusion\" else 0 for d in proposed_decisions]\naxes[0,0].plot(decisions_numeric, 'b-', alpha=0.7, label='Proposed (DKW)')\naxes[0,0].axhline(y=0, color='r', linestyle='--', alpha=0.7, label='Baseline (always fission)')\naxes[0,0].set_ylabel('Decision (1=Fusion, 0=Fission)')\naxes[0,0].set_xlabel('Example Index')\naxes[0,0].set_title('Decision Timeline')\naxes[0,0].legend()\naxes[0,0].grid(True, alpha=0.3)\n\n# 2. Cumulative error rate\nproposed_errors_cum = np.cumsum([r[\"error\"] for r in proposed_results])\nbaseline_errors_cum = np.cumsum([r[\"error\"] for r in baseline_results])\nexample_indices = range(1, len(proposed_results) + 1)\n\nproposed_error_rate = proposed_errors_cum / np.array(example_indices)\nbaseline_error_rate = baseline_errors_cum / np.array(example_indices)\n\naxes[0,1].plot(example_indices, proposed_error_rate, 'b-', label='Proposed (DKW)', alpha=0.8)\naxes[0,1].plot(example_indices, baseline_error_rate, 'r-', label='Baseline', alpha=0.8)\naxes[0,1].axhline(y=0.1, color='g', linestyle='--', alpha=0.7, label='Target (Îµ=0.1)')\naxes[0,1].set_ylabel('Cumulative Error Rate')\naxes[0,1].set_xlabel('Example Index')\naxes[0,1].set_title('Error Rate Evolution')\naxes[0,1].legend()\naxes[0,1].grid(True, alpha=0.3)\n\n# 3. Decision distribution\nmethods = ['Baseline', 'Proposed']\nfission_counts = [baseline_decisions.count('fission'), proposed_decisions.count('fission')]\nfusion_counts = [baseline_decisions.count('fusion'), proposed_decisions.count('fusion')]\n\nx = np.arange(len(methods))\nwidth = 0.35\n\naxes[1,0].bar(x - width/2, fission_counts, width, label='Fission', alpha=0.8, color='red')\naxes[1,0].bar(x + width/2, fusion_counts, width, label='Fusion', alpha=0.8, color='blue')\naxes[1,0].set_ylabel('Number of Decisions')\naxes[1,0].set_title('Decision Distribution')\naxes[1,0].set_xticks(x)\naxes[1,0].set_xticklabels(methods)\naxes[1,0].legend()\naxes[1,0].grid(True, alpha=0.3)\n\n# 4. DKW bound evolution (for last 100 samples)\ncontroller_demo = DKWController()\ndkw_bounds = []\nempirical_errors = []\nsample_sizes = []\n\nfor i, example in enumerate(full_dataset):\n    error = np.random.random() < example[\"difficulty\"]\n    controller_demo.add_observation(float(error))\n    \n    if len(controller_demo.samples) >= controller_demo.min_samples:\n        n = len(controller_demo.samples)\n        epsilon = controller_demo.dkw_epsilon(n)\n        empirical = np.mean(controller_demo.samples[-controller_demo.min_samples:])\n        \n        dkw_bounds.append(epsilon)\n        empirical_errors.append(empirical)\n        sample_sizes.append(n)\n\nif dkw_bounds:  # Only plot if we have data\n    axes[1,1].plot(sample_sizes, empirical_errors, 'b-', label='Empirical Error', alpha=0.8)\n    axes[1,1].fill_between(sample_sizes, \n                          np.array(empirical_errors) - np.array(dkw_bounds),\n                          np.array(empirical_errors) + np.array(dkw_bounds),\n                          alpha=0.3, label='DKW Confidence Band')\n    axes[1,1].axhline(y=0.1, color='g', linestyle='--', alpha=0.7, label='Target (Îµ=0.1)')\n    axes[1,1].set_ylabel('Error Rate')\n    axes[1,1].set_xlabel('Sample Size')\n    axes[1,1].set_title('DKW Bound Evolution')\n    axes[1,1].legend()\n    axes[1,1].grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.show()\n\nprint(f\"\\n=== PERFORMANCE SUMMARY ===\")\nprint(f\"DKW Controller efficiency: {fusion_counts[1]/len(proposed_results):.1%} fusion decisions\")\nprint(f\"Error rate difference: {(proposed_errors/len(proposed_results) - baseline_errors/len(baseline_results)):.3f}\")\nif dkw_bounds:\n    print(f\"Final DKW bound: Â±{dkw_bounds[-1]:.3f}\")\n    print(f\"Final empirical error: {empirical_errors[-1]:.3f}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Visualization and Analysis\n\nLet's visualize the controller's behavior over time and analyze its performance.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Run the experiment\nresults = run_experiment(full_dataset)\n\n# Display basic statistics\nbaseline_results = results[\"baseline\"]\nproposed_results = results[\"proposed\"]\n\nprint(\"=== EXPERIMENT RESULTS ===\")\nprint(f\"Total examples processed: {len(baseline_results)}\")\nprint()\n\n# Count decisions for each approach\nbaseline_decisions = [r[\"decision\"] for r in baseline_results]\nproposed_decisions = [r[\"decision\"] for r in proposed_results]\n\nprint(\"Baseline (always fission):\")\nprint(f\"  Fission decisions: {baseline_decisions.count('fission')}\")\nprint(f\"  Fusion decisions: {baseline_decisions.count('fusion')}\")\nprint()\n\nprint(\"Proposed (DKW controller):\")\nprint(f\"  Fission decisions: {proposed_decisions.count('fission')}\")\nprint(f\"  Fusion decisions: {proposed_decisions.count('fusion')}\")\nprint()\n\n# Calculate error rates\nbaseline_errors = sum(r[\"error\"] for r in baseline_results)\nproposed_errors = sum(r[\"error\"] for r in proposed_results)\n\nprint(\"Error rates:\")\nprint(f\"  Baseline error rate: {baseline_errors/len(baseline_results):.3f}\")\nprint(f\"  Proposed error rate: {proposed_errors/len(proposed_results):.3f}\")\n\n# Show first few results as examples\nprint(f\"\\nFirst 10 results (Proposed method):\")\nfor i in range(10):\n    r = proposed_results[i]\n    print(f\"  {r['id']}: {r['decision']} (error: {r['error']})\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Run Experiment\n\nLet's execute the experiment with our sample data and examine the results.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "def run_experiment(data):\n    \"\"\"Run DKW controller experiment with inlined data.\"\"\"\n    controller = DKWController()\n    results = {\"baseline\": [], \"proposed\": []}\n\n    for example in data:\n        # Simulate error occurrence based on difficulty\n        error = np.random.random() < example[\"difficulty\"]\n        controller.add_observation(float(error))\n        decision = controller.decide()\n\n        results[\"proposed\"].append({\n            \"id\": example[\"id\"],\n            \"decision\": decision,\n            \"error\": error,\n        })\n        results[\"baseline\"].append({\n            \"id\": example[\"id\"],\n            \"decision\": \"fission\",  # Always conservative\n            \"error\": error,\n        })\n\n    return results",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Experiment Function\n\nThe experiment function compares two approaches:\n1. **Baseline**: Always uses conservative \"fission\" mode\n2. **Proposed**: Uses the DKW controller to dynamically switch between fusion and fission based on observed error rates\n\nThe function simulates errors based on example difficulty and tracks decisions made by each approach.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Sample dataset - inlined to make notebook self-contained\n# This replaces the need for external \"../dataset_001/data_out.json\"\nsample_data = [\n    {\"id\": \"example_000\", \"difficulty\": 0.05},  # Easy example\n    {\"id\": \"example_001\", \"difficulty\": 0.08},  # Easy example  \n    {\"id\": \"example_002\", \"difficulty\": 0.15},  # Medium difficulty\n    {\"id\": \"example_003\", \"difficulty\": 0.03},  # Very easy\n    {\"id\": \"example_004\", \"difficulty\": 0.12},  # Medium difficulty\n    {\"id\": \"example_005\", \"difficulty\": 0.20},  # Hard example\n    {\"id\": \"example_006\", \"difficulty\": 0.07},  # Easy example\n    {\"id\": \"example_007\", \"difficulty\": 0.18},  # Medium-hard\n    {\"id\": \"example_008\", \"difficulty\": 0.04},  # Easy example\n    {\"id\": \"example_009\", \"difficulty\": 0.25},  # Very hard\n]\n\n# Extend the dataset for more realistic experimentation\nextended_data = []\nfor i in range(200):\n    # Generate examples with varying difficulty following a realistic distribution\n    if i < 100:\n        difficulty = np.random.beta(2, 10)  # Skewed towards easier examples\n    else:\n        difficulty = np.random.beta(3, 5)   # More mixed difficulty\n    \n    extended_data.append({\n        \"id\": f\"example_{i:03d}\",\n        \"difficulty\": min(max(difficulty, 0.01), 0.5)  # Clamp between 1% and 50%\n    })\n\n# Combine sample and extended data\nfull_dataset = sample_data + extended_data\n\nprint(f\"Created dataset with {len(full_dataset)} examples\")\nprint(f\"Difficulty range: {min(ex['difficulty'] for ex in full_dataset):.3f} - {max(ex['difficulty'] for ex in full_dataset):.3f}\")\nprint(f\"Mean difficulty: {np.mean([ex['difficulty'] for ex in full_dataset]):.3f}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Sample Data\n\nInstead of reading from external JSON files, we'll inline the sample data directly. The data consists of examples with varying difficulty levels that influence the probability of errors occurring.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "@dataclass\nclass DKWController:\n    \"\"\"DKW-guided fusion/fission controller.\"\"\"\n    epsilon_target: float = 0.10\n    delta: float = 0.05\n    min_samples: int = 100\n    hysteresis: float = 0.05\n\n    samples: list = field(default_factory=list)\n    current_state: str = \"fission\"\n\n    def dkw_epsilon(self, n: int) -> float:\n        \"\"\"Compute DKW epsilon for n samples.\"\"\"\n        if n < 2:\n            return 1.0\n        return np.sqrt(np.log(2 / self.delta) / (2 * n))\n\n    def add_observation(self, error: float) -> None:\n        \"\"\"Add error observation for calibration.\"\"\"\n        self.samples.append(error)\n\n    def decide(self) -> str:\n        \"\"\"Make fusion/fission decision with DKW guarantee.\"\"\"\n        n = len(self.samples)\n        if n < self.min_samples:\n            return self.current_state\n\n        epsilon = self.dkw_epsilon(n)\n        empirical_error = np.mean(self.samples[-self.min_samples:])\n        error_upper_bound = empirical_error + epsilon\n\n        if self.current_state == \"fusion\":\n            if error_upper_bound > self.epsilon_target + self.hysteresis:\n                self.current_state = \"fission\"\n        else:\n            if error_upper_bound < self.epsilon_target - self.hysteresis:\n                self.current_state = \"fusion\"\n\n        return self.current_state",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## DKW Controller Class\n\nThe `DKWController` class implements a fusion/fission decision system with statistical guarantees. It uses the **Dvoretzky-Kiefer-Wolfowitz inequality** to bound the error between the empirical and true error distributions.\n\n### Parameters:\n- `epsilon_target`: Target error rate threshold (default: 0.10)\n- `delta`: Confidence parameter for DKW bound (default: 0.05) \n- `min_samples`: Minimum samples before making decisions (default: 100)\n- `hysteresis`: Prevents oscillation between modes (default: 0.05)",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "\"\"\"Required imports for the DKW controller implementation.\"\"\"\nimport json\nimport numpy as np\nfrom dataclasses import dataclass, field\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\n# Set random seed for reproducibility\nnp.random.seed(42)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "# DKW Controller Implementation Demo\n## experiment_001: method.py\n\nThis notebook demonstrates a **DKW-guided fusion/fission controller** implementation. The controller uses the Dvoretzky-Kiefer-Wolfowitz (DKW) inequality to make statistically sound decisions about when to switch between fusion and fission modes based on error observations.\n\n### Key Features:\n- Statistical guarantees via DKW inequality\n- Hysteresis to prevent mode switching oscillation  \n- Configurable error tolerance and confidence levels",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}