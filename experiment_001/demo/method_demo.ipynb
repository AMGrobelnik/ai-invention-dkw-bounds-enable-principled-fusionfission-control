{
 "cells": [
  {
   "cell_type": "markdown",
   "source": "## 9. Conclusion\n\nThis notebook demonstrates a complete implementation of a DKW-guided fusion/fission controller. The key advantages of this approach include:\n\n- **Statistical rigor**: Theoretical guarantees on error bounds\n- **Adaptability**: Learns from observed data to make optimal decisions\n- **Robustness**: Hysteresis prevents unstable behavior\n- **Configurability**: Parameters can be tuned for different risk profiles\n\n### Next Steps\n\nYou can extend this implementation by:\n1. Adding more sophisticated error models\n2. Implementing different statistical bounds (Hoeffding, Bennett, etc.)\n3. Creating multi-armed bandit variants\n4. Adding online parameter adaptation\n5. Incorporating contextual information beyond difficulty\n\n### Experimental Design\n\nTo use this controller in practice:\n1. Define your fusion/fission scenarios\n2. Collect training data with known difficulty levels\n3. Tune parameters based on your risk tolerance\n4. Deploy with monitoring and periodic recalibration\n\n**Happy experimenting!** ðŸš€",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "## 8. Understanding the DKW Inequality\n\nThe **Dvoretzky-Kiefer-Wolfowitz (DKW) inequality** provides a theoretical foundation for our controller:\n\n$$P(|F_n(x) - F(x)| \\geq \\epsilon) \\leq 2e^{-2n\\epsilon^2}$$\n\nWhere:\n- $F_n(x)$ is the empirical distribution function\n- $F(x)$ is the true distribution function  \n- $n$ is the number of samples\n- $\\epsilon$ is the error bound\n\nIn our controller:\n- We use this to compute confidence bounds on the true error rate\n- The `dkw_epsilon` method implements: $\\epsilon = \\sqrt{\\frac{\\ln(2/\\delta)}{2n}}$\n- This ensures with probability $(1-\\delta)$, the true error rate is within $\\epsilon$ of our empirical estimate\n\n## Key Features\n\n1. **Statistical Guarantee**: The DKW bound provides theoretical confidence in our error estimates\n2. **Adaptive Behavior**: The controller switches between fusion/fission based on observed data\n3. **Hysteresis**: Prevents oscillation between modes by requiring clear evidence for transitions\n4. **Minimum Samples**: Ensures sufficient data before making adaptive decisions\n\n## Usage Tips\n\n- **Lower `epsilon_target`**: More aggressive, switches to fusion more readily\n- **Higher `epsilon_target`**: More conservative, prefers fission\n- **Lower `hysteresis`**: More sensitive to changes, switches more frequently\n- **Higher `hysteresis`**: More stable, requires stronger evidence to switch\n- **Higher `min_samples`**: Delays adaptive behavior until more data is collected",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Interactive parameter exploration\ndef explore_parameters(epsilon_target=0.10, delta=0.05, min_samples=100, hysteresis=0.05):\n    \"\"\"Explore how different parameters affect the controller's behavior.\"\"\"\n    print(f\"Testing with parameters:\")\n    print(f\"  epsilon_target: {epsilon_target}\")\n    print(f\"  delta: {delta}\")\n    print(f\"  min_samples: {min_samples}\")\n    print(f\"  hysteresis: {hysteresis}\")\n    \n    # Create controller with custom parameters\n    custom_controller = DKWController(\n        epsilon_target=epsilon_target,\n        delta=delta,\n        min_samples=min_samples,\n        hysteresis=hysteresis\n    )\n    \n    # Run experiment with custom controller\n    custom_results = {\"baseline\": [], \"proposed\": []}\n    \n    for example in sample_data:\n        error = np.random.random() < example[\"difficulty\"]\n        custom_controller.add_observation(float(error))\n        decision = custom_controller.decide()\n        \n        custom_results[\"proposed\"].append({\n            \"id\": example[\"id\"],\n            \"decision\": decision,\n            \"error\": error,\n        })\n        custom_results[\"baseline\"].append({\n            \"id\": example[\"id\"],\n            \"decision\": \"fission\",\n            \"error\": error,\n        })\n    \n    # Calculate metrics for custom controller\n    custom_df = pd.DataFrame(custom_results['proposed'])\n    custom_metrics = calculate_metrics(custom_df)\n    \n    fusion_ratio = custom_metrics['fusion_decisions'] / len(custom_results['proposed'])\n    \n    print(f\"\\nResults:\")\n    print(f\"  Fusion decisions: {custom_metrics['fusion_decisions']}/{len(sample_data)} ({fusion_ratio:.1%})\")\n    print(f\"  Overall error rate: {custom_metrics['overall_error_rate']:.3f}\")\n    if custom_metrics['fusion_decisions'] > 0:\n        print(f\"  Fusion error rate: {custom_metrics['fusion_error_rate']:.3f}\")\n    print(f\"  Fission error rate: {custom_metrics['fission_error_rate']:.3f}\")\n    \n    return custom_results\n\n# Try different parameter combinations\nprint(\"=== PARAMETER EXPLORATION ===\")\n\nprint(\"\\n1. More aggressive (lower target error rate):\")\nexplore_parameters(epsilon_target=0.05)\n\nprint(\"\\n2. More conservative (higher target error rate):\")\nexplore_parameters(epsilon_target=0.20)\n\nprint(\"\\n3. Less hysteresis (more sensitive to changes):\")\nexplore_parameters(hysteresis=0.01)\n\nprint(\"\\n4. More hysteresis (less sensitive to changes):\")\nexplore_parameters(hysteresis=0.10)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 7. Interactive Exploration\n\nTry modifying the controller parameters and see how they affect the decision-making process!",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Create visualizations\nfig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))\n\n# 1. Decision comparison\ndecisions_comparison = pd.DataFrame({\n    'Baseline': [baseline_metrics['fusion_decisions'], baseline_metrics['fission_decisions']],\n    'Proposed': [proposed_metrics['fusion_decisions'], proposed_metrics['fission_decisions']]\n}, index=['Fusion', 'Fission'])\n\ndecisions_comparison.plot(kind='bar', ax=ax1, color=['skyblue', 'lightcoral'])\nax1.set_title('Decision Frequency Comparison')\nax1.set_ylabel('Number of Decisions')\nax1.legend()\nax1.tick_params(axis='x', rotation=45)\n\n# 2. Error rate comparison\nerror_rates = pd.DataFrame({\n    'Baseline': [baseline_metrics['overall_error_rate']],\n    'Proposed': [proposed_metrics['overall_error_rate']]\n}, index=['Overall Error Rate'])\n\nerror_rates.plot(kind='bar', ax=ax2, color=['orange', 'green'])\nax2.set_title('Overall Error Rate Comparison')\nax2.set_ylabel('Error Rate')\nax2.legend()\nax2.tick_params(axis='x', rotation=45)\n\n# 3. Decision timeline for proposed method\ndecisions_timeline = [1 if dec == 'fusion' else 0 for dec in proposed_df['decision']]\nax3.plot(range(len(decisions_timeline)), decisions_timeline, 'o-', color='purple', alpha=0.7)\nax3.set_title('Decision Timeline (DKW Controller)')\nax3.set_xlabel('Example Index')\nax3.set_ylabel('Decision (0=Fission, 1=Fusion)')\nax3.set_ylim(-0.1, 1.1)\nax3.grid(True, alpha=0.3)\n\n# 4. Error occurrence vs difficulty\ndifficulties = [ex['difficulty'] for ex in sample_data]\nerrors = proposed_df['error'].astype(int)\nax4.scatter(difficulties, errors, alpha=0.6, c=['red' if err else 'blue' for err in errors])\nax4.set_title('Error Occurrence vs Difficulty')\nax4.set_xlabel('Difficulty Level')\nax4.set_ylabel('Error Occurred (0=No, 1=Yes)')\nax4.grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.show()\n\n# Summary statistics\nprint(\"\\n=== SUMMARY ===\")\nprint(f\"Total examples processed: {len(sample_data)}\")\nprint(f\"Average difficulty: {np.mean(difficulties):.3f}\")\nprint(f\"Baseline approach: Always fission (conservative)\")\nprint(f\"DKW approach: Adaptive based on error observations\")\nprint(f\"Fusion decisions made by DKW: {proposed_metrics['fusion_decisions']}/{len(sample_data)} ({fusion_ratio:.1%})\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 6. Visualization\n\nLet's create visualizations to better understand the controller's behavior and performance.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Convert results to DataFrames for easier analysis\nbaseline_df = pd.DataFrame(results['baseline'])\nproposed_df = pd.DataFrame(results['proposed'])\n\n# Calculate performance metrics\ndef calculate_metrics(df):\n    fusion_count = (df['decision'] == 'fusion').sum()\n    fission_count = (df['decision'] == 'fission').sum()\n    error_rate = df['error'].mean()\n    fusion_error_rate = df[df['decision'] == 'fusion']['error'].mean() if fusion_count > 0 else 0\n    fission_error_rate = df[df['decision'] == 'fission']['error'].mean() if fission_count > 0 else 0\n    \n    return {\n        'fusion_decisions': fusion_count,\n        'fission_decisions': fission_count,\n        'overall_error_rate': error_rate,\n        'fusion_error_rate': fusion_error_rate,\n        'fission_error_rate': fission_error_rate\n    }\n\nbaseline_metrics = calculate_metrics(baseline_df)\nproposed_metrics = calculate_metrics(proposed_df)\n\nprint(\"=== PERFORMANCE COMPARISON ===\")\nprint(f\"\\nBaseline (Always Fission):\")\nfor key, value in baseline_metrics.items():\n    if 'rate' in key:\n        print(f\"  {key}: {value:.3f}\")\n    else:\n        print(f\"  {key}: {value}\")\n\nprint(f\"\\nProposed (DKW Controller):\")\nfor key, value in proposed_metrics.items():\n    if 'rate' in key:\n        print(f\"  {key}: {value:.3f}\")\n    else:\n        print(f\"  {key}: {value}\")\n\n# Calculate performance improvement\nfusion_ratio = proposed_metrics['fusion_decisions'] / len(results['proposed'])\nprint(f\"\\nThe DKW controller chose fusion {fusion_ratio:.1%} of the time\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 5. Results Analysis\n\nLet's analyze the performance of both approaches and visualize the controller's decision-making process.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "def run_experiment(data):\n    \"\"\"Run DKW controller experiment with inlined data.\"\"\"\n    controller = DKWController()\n    results = {\"baseline\": [], \"proposed\": []}\n\n    for example in data:\n        # Simulate error occurrence based on difficulty\n        error = np.random.random() < example[\"difficulty\"]\n        controller.add_observation(float(error))\n        decision = controller.decide()\n\n        results[\"proposed\"].append({\n            \"id\": example[\"id\"],\n            \"decision\": decision,\n            \"error\": error,\n        })\n        results[\"baseline\"].append({\n            \"id\": example[\"id\"],\n            \"decision\": \"fission\",  # Always conservative\n            \"error\": error,\n        })\n\n    return results\n\n# Run the experiment\nprint(\"Running DKW controller experiment...\")\nresults = run_experiment(sample_data)\n\nprint(f\"Baseline decisions: {len(results['baseline'])} results\")\nprint(f\"Proposed decisions: {len(results['proposed'])} results\")\n\n# Show first few results\nprint(\"\\nFirst few baseline results:\")\nfor result in results['baseline'][:5]:\n    print(f\"  {result['id']}: {result['decision']}, error={result['error']}\")\n    \nprint(\"\\nFirst few proposed results:\")\nfor result in results['proposed'][:5]:\n    print(f\"  {result['id']}: {result['decision']}, error={result['error']}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 4. Experiment Function\n\nThe `run_experiment` function simulates the controller's behavior on our sample data. It compares:\n- **Baseline**: Always uses fission (conservative approach)\n- **Proposed**: Uses DKW controller to adaptively choose between fusion and fission",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Sample input data (replaces reading from ../dataset_001/data_out.json)\n# Each example has an ID and a difficulty level (0.0 = easy, 1.0 = very hard)\nsample_data = [\n    {\"id\": \"example_000\", \"difficulty\": 0.1},\n    {\"id\": \"example_001\", \"difficulty\": 0.05},\n    {\"id\": \"example_002\", \"difficulty\": 0.8},\n    {\"id\": \"example_003\", \"difficulty\": 0.2},\n    {\"id\": \"example_004\", \"difficulty\": 0.15},\n    {\"id\": \"example_005\", \"difficulty\": 0.9},\n    {\"id\": \"example_006\", \"difficulty\": 0.3},\n    {\"id\": \"example_007\", \"difficulty\": 0.1},\n    {\"id\": \"example_008\", \"difficulty\": 0.7},\n    {\"id\": \"example_009\", \"difficulty\": 0.05},\n    {\"id\": \"example_010\", \"difficulty\": 0.4},\n    {\"id\": \"example_011\", \"difficulty\": 0.6},\n    {\"id\": \"example_012\", \"difficulty\": 0.2},\n    {\"id\": \"example_013\", \"difficulty\": 0.3},\n    {\"id\": \"example_014\", \"difficulty\": 0.8},\n]\n\n# Expected output structure (for reference)\nexpected_output = {\n    \"baseline\": [\n        {\"id\": \"example_000\", \"decision\": \"fission\", \"error\": False},\n        {\"id\": \"example_001\", \"decision\": \"fission\", \"error\": False},\n        {\"id\": \"example_002\", \"decision\": \"fission\", \"error\": True}\n    ],\n    \"proposed\": [\n        {\"id\": \"example_000\", \"decision\": \"fission\", \"error\": False},\n        {\"id\": \"example_001\", \"decision\": \"fusion\", \"error\": False},\n        {\"id\": \"example_002\", \"decision\": \"fusion\", \"error\": True}\n    ]\n}\n\nprint(f\"Sample data contains {len(sample_data)} examples\")\nprint(f\"Difficulty range: {min(ex['difficulty'] for ex in sample_data):.2f} - {max(ex['difficulty'] for ex in sample_data):.2f}\")\nprint(\"\\nFirst few examples:\")\nfor ex in sample_data[:3]:\n    print(f\"  {ex['id']}: difficulty = {ex['difficulty']}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 3. Sample Data (Inlined)\n\nInstead of reading from external JSON files, we'll define our sample data directly in the notebook. This data represents examples with varying difficulty levels that affect error probability.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "@dataclass\nclass DKWController:\n    \"\"\"DKW-guided fusion/fission controller.\"\"\"\n    epsilon_target: float = 0.10\n    delta: float = 0.05\n    min_samples: int = 100\n    hysteresis: float = 0.05\n\n    samples: list = field(default_factory=list)\n    current_state: str = \"fission\"\n\n    def dkw_epsilon(self, n: int) -> float:\n        \"\"\"Compute DKW epsilon for n samples.\"\"\"\n        if n < 2:\n            return 1.0\n        return np.sqrt(np.log(2 / self.delta) / (2 * n))\n\n    def add_observation(self, error: float) -> None:\n        \"\"\"Add error observation for calibration.\"\"\"\n        self.samples.append(error)\n\n    def decide(self) -> str:\n        \"\"\"Make fusion/fission decision with DKW guarantee.\"\"\"\n        n = len(self.samples)\n        if n < self.min_samples:\n            return self.current_state\n\n        epsilon = self.dkw_epsilon(n)\n        empirical_error = np.mean(self.samples[-self.min_samples:])\n        error_upper_bound = empirical_error + epsilon\n\n        if self.current_state == \"fusion\":\n            if error_upper_bound > self.epsilon_target + self.hysteresis:\n                self.current_state = \"fission\"\n        else:\n            if error_upper_bound < self.epsilon_target - self.hysteresis:\n                self.current_state = \"fusion\"\n\n        return self.current_state\n\n# Create an instance to demonstrate\ncontroller = DKWController()\nprint(f\"Controller initialized in {controller.current_state} mode\")\nprint(f\"Target error rate: {controller.epsilon_target}\")\nprint(f\"Confidence level: {1 - controller.delta}\")\nprint(f\"Minimum samples required: {controller.min_samples}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 2. DKW Controller Class\n\nThe `DKWController` class implements a decision-making system that uses the DKW inequality to maintain statistical guarantees on error bounds. Here's what each parameter does:\n\n- **epsilon_target**: Target error rate threshold (10% in this example)\n- **delta**: Confidence level parameter (5% significance level)\n- **min_samples**: Minimum samples needed before making decisions\n- **hysteresis**: Prevents oscillation between modes by creating a buffer zone",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "\"\"\"DKW Controller Implementation.\"\"\"\nimport json\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom dataclasses import dataclass, field\n\n# Set random seed for reproducibility\nnp.random.seed(42)\nprint(\"Libraries imported successfully!\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 1. Setup and Imports\n\nFirst, let's import the required libraries and set up our environment.",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "# DKW Controller Implementation Demo\n\nThis notebook demonstrates a **DKW-guided fusion/fission controller** implementation. The controller uses the Dvoretzky-Kiefer-Wolfowitz (DKW) inequality to make statistically-grounded decisions between fusion and fission modes based on observed error rates.\n\n## Overview\n- **Fusion mode**: Aggressive approach with potentially higher performance but more risk\n- **Fission mode**: Conservative approach with lower risk but potentially reduced performance\n- **DKW guarantee**: Statistical confidence bounds on error rates to guide decision making",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}