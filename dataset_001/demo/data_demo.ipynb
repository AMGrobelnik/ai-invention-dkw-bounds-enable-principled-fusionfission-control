{
 "cells": [
  {
   "cell_type": "code",
   "source": "# Uncomment the lines below if you want to save to a file\n# with open(\"data_out.json\", \"w\") as f:\n#     json.dump(processed_data, f, indent=2)\n# print(\"Data saved to data_out.json\")\n\nprint(\"Note: File saving is commented out to keep this notebook self-contained\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Optional: Save to File\n\nIf you want to save the processed data to a JSON file (as in the original script), you can run this cell:",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Process the data using our function\nprocessed_data = collect_data(SAMPLE_DATASET)\n\nprint(f\"Collected {len(processed_data)} examples\")\nprint(\"\\nProcessed data:\")\nprint(json.dumps(processed_data, indent=2))",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Process the Data\n\nLet's run the data collection function and see the results:",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "def collect_data(dataset: List[Dict[str, str]]) -> List[Dict[str, Any]]:\n    \"\"\"Collect benchmark data for DKW controller evaluation.\n    \n    Args:\n        dataset: List of dictionaries with 'question' and 'answer' keys\n        \n    Returns:\n        List of processed examples with metadata\n    \"\"\"\n    data = []\n    for i, example in enumerate(dataset):\n        data.append({\n            \"id\": f\"example_{i:03d}\",\n            \"question\": example[\"question\"],\n            \"answer\": example[\"answer\"],\n            \"difficulty\": len(example[\"question\"]) / 100,  # Simple proxy based on question length\n        })\n    \n    return data",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Data Collection Function\n\nThe main function processes the raw dataset and adds metadata such as difficulty scores:",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Sample data inlined from the original JSON output\n# This represents what would typically be loaded from HuggingFace datasets\nSAMPLE_DATASET = [\n    {\n        \"question\": \"What is 2+2?\",\n        \"answer\": \"4\"\n    },\n    {\n        \"question\": \"If x=5, what is 2x?\", \n        \"answer\": \"10\"\n    },\n    {\n        \"question\": \"Solve: 3y + 6 = 15\",\n        \"answer\": \"y=3\"\n    }\n]\n\nprint(f\"Loaded {len(SAMPLE_DATASET)} sample questions\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Sample Data\n\nInstead of loading from external sources, we'll use this sample data that represents the kind of mathematical problems in the GSM8K dataset:",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "\"\"\"Dataset collection script for DKW benchmark.\"\"\"\nimport json\nfrom typing import List, Dict, Any",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Overview\n\nThis notebook contains a dataset collection script that was originally designed to load data from HuggingFace's GSM8K dataset. For demonstration purposes, this version uses inline sample data to make the notebook completely self-contained.\n\n### What this notebook does:\n1. Defines a data collection function\n2. Uses sample benchmark data (inlined from JSON)\n3. Processes the data to add metadata like difficulty scores\n4. Displays the results in an easy-to-understand format",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "# Dataset Collection for DKW Benchmark\n\n**Artifact ID:** dataset_001  \n**Name:** data.py\n\nThis notebook demonstrates a dataset collection script for DKW controller evaluation. The original script has been converted into an interactive, self-contained notebook that processes benchmark data without external dependencies.",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}