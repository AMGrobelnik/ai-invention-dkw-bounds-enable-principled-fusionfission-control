{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Collection for DKW Benchmark\n",
    "\n",
    "This notebook demonstrates the dataset collection script for DKW controller evaluation. The script processes benchmark data from the GSM8K dataset and formats it for evaluation purposes.\n",
    "\n",
    "**Original Artifact:** data.py  \n",
    "**Purpose:** Collect and format benchmark data for mathematical reasoning tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Dependencies\n",
    "\n",
    "First, let's import the required libraries for data processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Dataset collection script for DKW benchmark.\"\"\"\n",
    "import json\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "# Note: In the original script, this would be: from datasets import load_dataset\n",
    "# For this self-contained notebook, we'll use inline data instead"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Dataset\n",
    "\n",
    "Since this is a self-contained notebook, we'll simulate the GSM8K dataset with sample data instead of loading from HuggingFace. In the original script, this would be loaded using `load_dataset(\"gsm8k\", \"main\", split=\"test[:200]\")`.  \n",
    "\n",
    "Here we include some mathematical reasoning questions that represent the type of data from GSM8K:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulated GSM8K dataset samples (normally loaded from HuggingFace)\n",
    "simulated_dataset = [\n",
    "    {\n",
    "        \"question\": \"Janet's ducks lay 16 eggs per day. She eats three for breakfast every morning and bakes muffins for her friends every day with four. She sells the remainder at the farmers' market daily for $2 per fresh duck egg. How much in dollars does she make every day at the farmers' market?\",\n",
    "        \"answer\": \"Janet sells 16 - 3 - 4 = 9 duck eggs a day. She makes 9 * 2 = $18 every day at the farmer's market.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"A robe takes 2 bolts of blue fiber and half that much white fiber. How many bolts are needed?\", \n",
    "        \"answer\": \"It takes 2 bolts of blue fiber and 2/2 = 1 bolt of white fiber. So the total is 2 + 1 = 3 bolts.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Josh decides to try flipping a house. He buys a house for $80,000 and then puts in $50,000 in repairs. This increased the value of the house by 150%. How much profit did he make?\",\n",
    "        \"answer\": \"The cost of the house and repairs came out to 80,000+50,000=$130,000. He increased the value of the house by 80,000*1.5=120,000. So the new value of the house is 120,000+80,000=$200,000. So he made a profit of 200,000-130,000=$70,000.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"James decides to run 3 sprints 3 times a week. He runs 60 meters each sprint. How many total meters does he run a week?\",\n",
    "        \"answer\": \"He runs 3*3=9 sprints a week. So he runs 9*60=540 meters a week.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Every day, Wendi feeds each of her chickens three cups of mixed chicken feed, containing seeds, mealworms and vegetables. She gives the chickens their feed in three separate meals. In the morning, she gives each chicken 15 grams of seeds. In the afternoon, she gives each chicken 25 grams of mealworms. How many grams of vegetables does she give each chicken in the evening?\",\n",
    "        \"answer\": \"Each chicken gets 3 cups of feed daily, and this is split into 3 meals. The weight of feed per meal is not specified, but we know the seeds are 15 grams and mealworms are 25 grams. If we assume the total daily feed per chicken weighs 150 grams (50 grams per meal), then vegetables would be 150 - 15 - 25 = 110 grams. However, without the total weight specified, we can't determine the exact vegetable amount.\"\n",
    "    }\n",
    "]\n",
    "\n",
    "print(f\"Loaded {len(simulated_dataset)} sample questions\")\n",
    "print(f\"\\nFirst question preview: {simulated_dataset[0]['question'][:100]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing Function\n",
    "\n",
    "The `collect_data()` function processes the raw dataset and adds additional metadata like difficulty scoring based on question length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_data() -> List[Dict[str, Any]]:\n",
    "    \"\"\"Collect benchmark data for DKW controller evaluation.\"\"\"\n",
    "    \n",
    "    # In the original script, this would be:\n",
    "    # ds = load_dataset(\"gsm8k\", \"main\", split=\"test[:200]\")\n",
    "    # Here we use our simulated dataset instead\n",
    "    ds = simulated_dataset\n",
    "\n",
    "    data = []\n",
    "    for i, example in enumerate(ds):\n",
    "        processed_item = {\n",
    "            \"id\": f\"example_{i:03d}\",\n",
    "            \"question\": example[\"question\"],\n",
    "            \"answer\": example[\"answer\"],\n",
    "            \"difficulty\": len(example[\"question\"]) / 100,  # Simple proxy for difficulty\n",
    "        }\n",
    "        data.append(processed_item)\n",
    "\n",
    "    return data\n",
    "\n",
    "print(\"âœ… Data processing function defined successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute Data Collection\n",
    "\n",
    "Let's run the data collection function and examine the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute the data collection\n",
    "data = collect_data()\n",
    "\n",
    "print(f\"Collected {len(data)} examples\")\n",
    "print(\"\\nFirst few examples:\")\n",
    "for item in data[:3]:\n",
    "    print(f\"- ID: {item['id']}\")\n",
    "    print(f\"  Question: {item['question'][:60]}...\")\n",
    "    print(f\"  Answer: {item['answer'][:60]}...\")\n",
    "    print(f\"  Difficulty: {item['difficulty']:.2f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View Complete Dataset\n",
    "\n",
    "Let's examine the complete processed dataset structure that would normally be saved to `data_out.json`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the complete processed dataset\n",
    "print(\"Complete processed dataset:\")\n",
    "print(json.dumps(data, indent=2))\n",
    "\n",
    "# In the original script, this would be saved to a file:\n",
    "# with open(\"data_out.json\", \"w\") as f:\n",
    "#     json.dump(data, f, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expected Output Reference\n",
    "\n",
    "For comparison, here's the expected output structure that was provided in the original specification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expected output format (from original data_out.json)\n",
    "expected_output = [\n",
    "    {\n",
    "        \"id\": \"example_000\",\n",
    "        \"question\": \"What is 2+2?\",\n",
    "        \"answer\": \"4\",\n",
    "        \"difficulty\": 0.15\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"example_001\", \n",
    "        \"question\": \"If x=5, what is 2x?\",\n",
    "        \"answer\": \"10\",\n",
    "        \"difficulty\": 0.22\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"example_002\",\n",
    "        \"question\": \"Solve: 3y + 6 = 15\",\n",
    "        \"answer\": \"y=3\",\n",
    "        \"difficulty\": 0.28\n",
    "    }\n",
    "]\n",
    "\n",
    "print(\"Expected output format:\")\n",
    "print(json.dumps(expected_output, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File Saving (Original Script Behavior)\n",
    "\n",
    "In the original script, the final step was to save the data to a JSON file and print a summary. Let's replicate that behavior:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate the original script's main execution\n",
    "if __name__ == \"__main__\":\n",
    "    # This replicates the original script's main block\n",
    "    final_data = collect_data()\n",
    "    \n",
    "    # In original script: with open(\"data_out.json\", \"w\") as f: json.dump(data, f, indent=2)\n",
    "    print(\"ðŸ’¾ [Simulated] Data would be saved to 'data_out.json'\")\n",
    "    \n",
    "    # Original script's final print statement\n",
    "    print(f\"Collected {len(final_data)} examples\")\n",
    "    \n",
    "    print(\"\\nðŸŽ¯ Dataset collection completed successfully!\")\n",
    "    print(\"ðŸ“Š Data is now ready for DKW benchmark evaluation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage Notes & Customization\n",
    "\n",
    "### How to use this notebook:\n",
    "1. **Self-contained**: This notebook runs without any external files or dependencies\n",
    "2. **Customizable**: Modify the `simulated_dataset` to test with your own questions\n",
    "3. **Extensible**: Add new fields to the output format by modifying the `collect_data()` function\n",
    "\n",
    "### Original vs Notebook differences:\n",
    "- **Original**: Loads data from HuggingFace datasets library\n",
    "- **Notebook**: Uses inline sample data for demonstration\n",
    "- **Original**: Saves output to `data_out.json` file  \n",
    "- **Notebook**: Displays output directly in cells\n",
    "\n",
    "### To restore original functionality:\n",
    "1. Install dependencies: `pip install datasets`\n",
    "2. Replace `simulated_dataset` with: `load_dataset(\"gsm8k\", \"main\", split=\"test[:200]\")`\n",
    "3. Uncomment the file writing code to save to `data_out.json`\n",
    "\n",
    "### Difficulty Metric:\n",
    "The current difficulty calculation (`len(question) / 100`) is a simple proxy. You could enhance this with:\n",
    "- Word count-based metrics\n",
    "- Mathematical complexity analysis\n",
    "- Machine learning-based difficulty prediction"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}