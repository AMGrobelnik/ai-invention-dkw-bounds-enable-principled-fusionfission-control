{
 "cells": [
  {
   "cell_type": "markdown",
   "source": "## Customization Instructions\n\nThis notebook is completely self-contained and can be easily modified:\n\n### To add more data:\n1. Extend the `sample_dataset` list with additional question-answer pairs\n2. Re-run the processing cells\n\n### To change the difficulty calculation:\n1. Modify the difficulty calculation in the `collect_data()` function\n2. Current method: `len(example[\"question\"]) / 100` (question length proxy)\n3. Alternative methods could include: word count, complexity analysis, etc.\n\n### To save output to file:\nUncomment and modify this code in any cell:\n```python\n# with open(\"data_out.json\", \"w\") as f:\n#     json.dump(processed_data, f, indent=2)\n```\n\n### To use with real HuggingFace datasets:\n1. Install: `pip install datasets`\n2. Replace the `sample_dataset` with: `load_dataset(\"gsm8k\", \"main\", split=\"test[:200]\")`\n3. Add back the original imports",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Expected output format from original requirements\nexpected_output = [\n    {\n        \"id\": \"example_000\",\n        \"question\": \"What is 2+2?\",\n        \"answer\": \"4\",\n        \"difficulty\": 0.15\n    },\n    {\n        \"id\": \"example_001\",\n        \"question\": \"If x=5, what is 2x?\",\n        \"answer\": \"10\",\n        \"difficulty\": 0.22\n    },\n    {\n        \"id\": \"example_002\",\n        \"question\": \"Solve: 3y + 6 = 15\",\n        \"answer\": \"y=3\",\n        \"difficulty\": 0.28\n    }\n]\n\nprint(\"Expected output format:\")\nprint(json.dumps(expected_output, indent=2))",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Expected Output Reference\n\nFor comparison, here's the expected output format (from the original artifact requirements):",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# In the original script, this would save to a file:\n# with open(\"data_out.json\", \"w\") as f:\n#     json.dump(data, f, indent=2)\n\n# Instead, let's display the JSON output that would have been saved\nprint(\"JSON output (would be saved to data_out.json):\")\nprint(\"=\" * 50)\nprint(json.dumps(processed_data, indent=2))\n\nprint(f\"\\nOriginal script would output: 'Collected {len(processed_data)} examples'\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## JSON Output\n\nIn the original script, the processed data would be saved to `data_out.json`. Here's what that output would look like:",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Display all processed data\nprint(\"All processed examples:\")\nprint(\"=\" * 50)\n\nfor item in processed_data:\n    print(f\"\\nID: {item['id']}\")\n    print(f\"Difficulty: {item['difficulty']:.2f}\")\n    print(f\"Question: {item['question'][:100]}{'...' if len(item['question']) > 100 else ''}\")\n    print(f\"Answer: {item['answer'][:100]}{'...' if len(item['answer']) > 100 else ''}\")\n    print(\"-\" * 30)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## View All Processed Data\n\nLet's examine all the processed examples and their difficulty scores:",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "def collect_data(dataset):\n    \"\"\"Collect benchmark data for DKW controller evaluation.\"\"\"\n    # Modified to work with inline data instead of HuggingFace datasets\n    # Original: ds = load_dataset(\"gsm8k\", \"main\", split=\"test[:200]\")\n    \n    data = []\n    for i, example in enumerate(dataset):\n        data.append({\n            \"id\": f\"example_{i:03d}\",\n            \"question\": example[\"question\"],\n            \"answer\": example[\"answer\"],\n            \"difficulty\": len(example[\"question\"]) / 100,  # Simple proxy based on question length\n        })\n\n    return data\n\n# Test the function with our sample data\nprocessed_data = collect_data(sample_dataset)\nprint(f\"Processed {len(processed_data)} examples\")\nprint(\"\\nFirst example:\")\nprint(json.dumps(processed_data[0], indent=2))",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Data Processing Function\n\nThe `collect_data()` function processes the raw dataset and adds metadata like difficulty scores:",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Sample data that mimics the GSM8K dataset structure\n# In the original script, this would come from: load_dataset(\"gsm8k\", \"main\", split=\"test[:200]\")\nsample_dataset = [\n    {\n        \"question\": \"Janet's ducks lay 16 eggs per day. She eats 3 for breakfast every morning and bakes 4 into muffins for her friends every day. She sells the remainder at the farmers' market daily for $2 per fresh duck egg. How much in dollars does she make every day?\",\n        \"answer\": \"Janet's ducks lay 16 eggs per day.\\nShe eats 3 for breakfast every morning.\\nShe bakes 4 into muffins for her friends every day.\\nSo she uses 3 + 4 = 7 eggs.\\nShe has 16 - 7 = 9 eggs left to sell.\\nShe sells them for $2 each, so she makes 9 * $2 = $18 every day.\\n#### 18\"\n    },\n    {\n        \"question\": \"A robe takes 2 bolts of blue fiber and half that much white fiber. How many bolts of fiber does it take?\",\n        \"answer\": \"It takes 2 bolts of blue fiber.\\nIt takes half that much white fiber, so 2 / 2 = 1 bolt of white fiber.\\nSo in total it takes 2 + 1 = 3 bolts of fiber.\\n#### 3\"\n    },\n    {\n        \"question\": \"Josh decides to try flipping a house. He buys a house for $80,000 and then puts in $50,000 in repairs. This increased the value of the house by 150%. How much profit did he make?\",\n        \"answer\": \"He bought the house for $80,000 and put in $50,000 in repairs for a total cost of 80,000 + 50,000 = $130,000.\\nThe value increased by 150%, so the new value is 80,000 * 2.5 = $200,000.\\nSo he made a profit of 200,000 - 130,000 = $70,000.\\n#### 70000\"\n    },\n    {\n        \"question\": \"James decides to run 3 sprints 3 times a week. He runs 60 meters each sprint. How many meters does he run a week?\",\n        \"answer\": \"He runs 3 sprints 3 times a week so he runs 3*3 = 9 sprints a week.\\nEach sprint is 60 meters so he runs 9*60 = 540 meters a week.\\n#### 540\"\n    },\n    {\n        \"question\": \"Every day, Wendi feeds each of her chickens three cups of mixed chicken feed, containing seeds, mealworms, and vegetables. She gives the chickens their feed in three separate meals. How many cups of feed does she give the chickens in the first meal of the day?\",\n        \"answer\": \"If each chicken gets 3 cups of feed per day, and the feed is given in 3 meals, then each chicken gets 3/3 = 1 cup of feed per meal.\\nThe question asks about the first meal of the day for all the chickens, but doesn't specify how many chickens there are. However, the question seems to be asking about the per-chicken amount in the first meal.\\n#### 1\"\n    }\n]\n\nprint(f\"Sample dataset contains {len(sample_dataset)} examples\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Sample Data\n\nInstead of loading from HuggingFace datasets, we'll use inline sample data that mimics the structure of the GSM8K dataset:",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "\"\"\"Dataset collection script for DKW benchmark.\"\"\"\nimport json\n# Note: We've removed the 'datasets' import as we're using inline data instead",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Overview\n\nThis notebook processes mathematical question-answer data for benchmarking purposes. Instead of loading data from external HuggingFace datasets, we'll use inline sample data to make this notebook completely self-contained.\n\nThe original script would:\n1. Load data from the GSM8K dataset\n2. Process each example to add metadata like difficulty scores\n3. Save the processed data to a JSON file\n\nIn this notebook version, we'll demonstrate the same functionality with sample data.",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "# Dataset Collection Script for DKW Benchmark\n\n**Artifact ID:** dataset_001  \n**Original File:** data.py\n\nThis notebook demonstrates dataset collection and processing for DKW controller evaluation. The original script has been converted to be completely self-contained with inline sample data.",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}